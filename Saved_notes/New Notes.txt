
    
    
    
    - **Recurrent Neural Networks (RNNs)**
  - Used for sequential data with dependencies between elements
  - Examples: Natural language processing (NLP), speech recognition
  - Types of RNNs include:
    - Long short-term memory (LSTM)
    - Gated recurrent unit (GRU)

- **Convolutional Neural Networks (CNNs)**
  - Used for data with grid-like structure, such as images and audio
  - Feature extraction is done through convolutions, allowing for spatial relationships to be learned
  - Examples: Image classification, object detection
  - Layers in CNNs include:
    - Convolutional layers
    - Pooling layers
    - Fully connected layers

- **K-Nearest Neighbors (KNN)**
  - Non-parametric algorithm for classification and regression
  - Assigns a label or value to a new data point based on the majority vote or average of its k nearest neighbors in the training set
  - Examples: Handwritten digit recognition, medical diagnosis
  - Hyperparameters:
    - Number of neighbors (k)
    - Distance metric used for calculating nearest neighbors
    
    
    Question: What is Sigmoid?
    
    Answer: The provided notes do not include any mention of Sigmoid activation function.

According to my knowledge, Sigmoid is a non-linear activation function commonly used in neural networks. It maps input values to a range between 0 and 1, making it suitable for binary classification tasks. It is often employed in the output layer of neural networks to produce a probability of class membership.
    
    
    
    Question: What is Sigmoid?
    
    Answer: The provided notes do not include any mention of the Sigmoid activation function.

According to my knowledge, the Sigmoid function is a non-linear activation function commonly used in neural networks. It maps input values to a range between 0 and 1, making it suitable for binary classification tasks. It is often employed in the output layer of neural networks to produce a probability of class membership.

**Example:**

In a binary classification task, the Sigmoid function can be used in the output layer to calculate the probability of a data point belonging to a specific class. The input to the Sigmoid function is a weighted sum of the inputs from the previous layer. The output of the Sigmoid function is a value between 0 and 1, where 0 represents a low probability and 1 represents a high probability of belonging to the class.
    
    
    
    Question: what is sigmoid function ?
    
    Answer: *

The Sigmoid function is a non-linear activation function commonly used in neural networks. It maps input values to a range between 0 and 1, making it suitable for binary classification tasks. It is often employed in the output layer of neural networks to produce a probability of class membership.

**Example:**

In a binary classification task, the Sigmoid function can be used in the output layer to calculate the probability of a data point belonging to a specific class. The input to the Sigmoid function is a weighted sum of the inputs from the previous layer. The output of the Sigmoid function is a value between 0 and 1, where 0 represents a low probability and 1 represents a high probability of belonging to the class.
    
    